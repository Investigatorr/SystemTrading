{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 크롤러 스킵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 필요시 추가예정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 뉴스,주가 데이터 임포트\n",
    "## 형태소 분석 ~ 전처리 ~ 익스포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "from pandas_datareader import data as pdr\n",
    "import fix_yahoo_finance as yf\n",
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "\n",
    "#from eunjeon import Mecab\n",
    "#mecab = Mecab()\n",
    "\n",
    "# class 정의 => 기능은 뉴스랑 주가데이터 임포트 ~ 전처리데이터 익스포트\n",
    "# filename : \"news_all.csv\"\n",
    "# filepath : \"./dataset/\"\n",
    "class data_import_preprocess():\n",
    "    def news_get(self, filepath):\n",
    "        df = pd.read_csv(filepath, encoding = 'utf-8 sig', engine = 'python')\n",
    "        return df\n",
    "\n",
    "    # 두번째 메소드 : news데이터 전처리 밑 명사로 나눠주는 함수\n",
    "    # 1param - InputData\n",
    "    # 칼럼 이름은 고정값(아래 함수에서 지정한 칼럼이름만 처리 가능)\n",
    "    def news_timecleansing(self, data):\n",
    "        # Time 칼럼의 노이즈 제거\n",
    "        df_news = data\n",
    "        df_news['TIME'] = df_news['TIME'].apply(lambda x: x[-14:]) # 연도 앞에 붙은 문자열 제거 (뒤에서 14개문자만 자르기)\n",
    "        df_news['TIME'] = df_news['TIME'].apply(lambda x: x[:10]) # 분과 초 제거 (앞에서 10개 문자만 자르기)\n",
    "        df_news['TIME'] = pd.to_datetime(df_news['TIME'])# 표준 날짜타입으로 변환\n",
    "        return df_news\n",
    "    \n",
    "    # 형태소분석기로 명사만 추출하기\n",
    "    # 1param - InputData / 2param - 사용할 형태소 분석기\n",
    "    def noun_extracting(self, df, extractor):        \n",
    "        df['title+body'] = df.apply(lambda x : '{}|||{}'.format(x['TITLE'], x['BODY']), axis = 1) # title과 body 합쳐서 새로운 칼럼 추가  구분자 : |||\n",
    "        df['title+body'] = df['title+body'].astype(str)\n",
    "        df['NOUNS'] = df['title+body'].apply(lambda x : '{}'.format(extractor.nouns(x))) # ''씌워줘야 list 안 원소들이 join해서 붙는다.\n",
    "        return df\n",
    "\n",
    "    # 1param - 종목코드 / 2param - startdate / 3param - enddate\n",
    "    def stock_get(self, keycode, startdate, enddate):\n",
    "        yf.pdr_override()\n",
    "        df_stock = pdr.get_data_yahoo(keycode, start = startdate, end = enddate)\n",
    "        df_stock['day1T'] = df_stock['Close'].shift(-1)\n",
    "        df_stock['day3T'] = df_stock['Close'].shift(-3)\n",
    "        df_stock['day5T'] = df_stock['Close'].shift(-5)\n",
    "        df_stock['day10T'] = df_stock['Close'].shift(-10)\n",
    "        return df_stock\n",
    "    \n",
    "    def news_stock_concat(self, news, stock):\n",
    "        news.rename(columns={'TIME': 'Date'}, inplace = True)\n",
    "        news = news.groupby('Date').agg({'NOUNS' : lambda x : ''.join(x)}) \n",
    "        news_stock = news.join(df_stock, how = 'outer')\n",
    "        news_stock = news_stock.dropna()\n",
    "        return news_stock\n",
    "        \n",
    "    def making_new_columns(self, df):\n",
    "        df['Diff1'] = df['day1T'] - df['Close']\n",
    "        df['Diff3'] = df['day3T'] - df['Close']\n",
    "        df['Diff5'] = df['day5T'] - df['Close']\n",
    "        df['Diff10'] = df['day10T'] - df['Close']\n",
    "        df['Diff1_per'] = round(df['Diff1'] / df['Close'] * 100, 2)\n",
    "        df['Diff3_per'] = round(df['Diff3'] / df['Close'] * 100, 2)\n",
    "        df['Diff5_per'] = round(df['Diff5'] / df['Close'] * 100, 2)\n",
    "        df['Diff10_per'] = round(df['Diff10'] / df['Close'] * 100, 2)\n",
    "        bins = [-100, 0, 100]\n",
    "        labels = [-1, 1]\n",
    "        df['Diff1_clf'] = pd.cut(df[\"Diff1_per\"], bins, labels = labels)\n",
    "        df['Diff3_clf'] = pd.cut(df[\"Diff3_per\"], bins, labels = labels)\n",
    "        df['Diff5_clf'] = pd.cut(df[\"Diff5_per\"], bins, labels = labels)\n",
    "        df['Diff10_clf'] = pd.cut(df[\"Diff10_per\"], bins, labels = labels)\n",
    "        df.drop(['High', 'Low', 'Adj Close', 'Volume'], axis=1, inplace = True)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 클래스 내 메소드 순차적 실행하는 예제코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 downloaded\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NOUNS</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>day1T</th>\n",
       "      <th>day3T</th>\n",
       "      <th>day5T</th>\n",
       "      <th>day10T</th>\n",
       "      <th>Diff1</th>\n",
       "      <th>Diff3</th>\n",
       "      <th>Diff5</th>\n",
       "      <th>Diff10</th>\n",
       "      <th>Diff1_per</th>\n",
       "      <th>Diff3_per</th>\n",
       "      <th>Diff5_per</th>\n",
       "      <th>Diff10_per</th>\n",
       "      <th>Diff1_clf</th>\n",
       "      <th>Diff3_clf</th>\n",
       "      <th>Diff5_clf</th>\n",
       "      <th>Diff10_clf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-12-01</th>\n",
       "      <td>['내년', '증시', '정기', '대비', '자산', '배분', '펀드', '주목...</td>\n",
       "      <td>50800.0</td>\n",
       "      <td>50840.0</td>\n",
       "      <td>51340.0</td>\n",
       "      <td>50020.0</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>50620.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>-820.0</td>\n",
       "      <td>1160.0</td>\n",
       "      <td>-220.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>-1.61</td>\n",
       "      <td>2.28</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-04</th>\n",
       "      <td>['투자자', '항의', '빗발', '친', '모간', '스탠리', '삼성', '전...</td>\n",
       "      <td>50840.0</td>\n",
       "      <td>51340.0</td>\n",
       "      <td>51260.0</td>\n",
       "      <td>50740.0</td>\n",
       "      <td>51780.0</td>\n",
       "      <td>51200.0</td>\n",
       "      <td>-80.0</td>\n",
       "      <td>-600.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>-140.0</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-1.17</td>\n",
       "      <td>0.86</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-05</th>\n",
       "      <td>['이', '종목', '왜', '오늘', '특징', '주', '내년', '기대', ...</td>\n",
       "      <td>50600.0</td>\n",
       "      <td>51260.0</td>\n",
       "      <td>50020.0</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>52100.0</td>\n",
       "      <td>51560.0</td>\n",
       "      <td>-1240.0</td>\n",
       "      <td>740.0</td>\n",
       "      <td>840.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>-2.42</td>\n",
       "      <td>1.44</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.59</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-06</th>\n",
       "      <td>['서울대', '시흥', '캠', '삼성', '현대차', '자율', '주행', '연...</td>\n",
       "      <td>51260.0</td>\n",
       "      <td>50020.0</td>\n",
       "      <td>50740.0</td>\n",
       "      <td>51780.0</td>\n",
       "      <td>51320.0</td>\n",
       "      <td>49140.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>1760.0</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>-880.0</td>\n",
       "      <td>1.44</td>\n",
       "      <td>3.52</td>\n",
       "      <td>2.60</td>\n",
       "      <td>-1.76</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-07</th>\n",
       "      <td>['과', '뇌물', '공범', '방', '특검', '최', '실', '공모', '...</td>\n",
       "      <td>50040.0</td>\n",
       "      <td>50740.0</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>52100.0</td>\n",
       "      <td>51060.0</td>\n",
       "      <td>49700.0</td>\n",
       "      <td>1260.0</td>\n",
       "      <td>1360.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>-1040.0</td>\n",
       "      <td>2.48</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0.63</td>\n",
       "      <td>-2.05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        NOUNS     Open  \\\n",
       "Date                                                                     \n",
       "2017-12-01  ['내년', '증시', '정기', '대비', '자산', '배분', '펀드', '주목...  50800.0   \n",
       "2017-12-04  ['투자자', '항의', '빗발', '친', '모간', '스탠리', '삼성', '전...  50840.0   \n",
       "2017-12-05  ['이', '종목', '왜', '오늘', '특징', '주', '내년', '기대', ...  50600.0   \n",
       "2017-12-06  ['서울대', '시흥', '캠', '삼성', '현대차', '자율', '주행', '연...  51260.0   \n",
       "2017-12-07  ['과', '뇌물', '공범', '방', '특검', '최', '실', '공모', '...  50040.0   \n",
       "\n",
       "              Close    day1T    day3T    day5T   day10T   Diff1   Diff3  \\\n",
       "Date                                                                      \n",
       "2017-12-01  50840.0  51340.0  50020.0  52000.0  50620.0   500.0  -820.0   \n",
       "2017-12-04  51340.0  51260.0  50740.0  51780.0  51200.0   -80.0  -600.0   \n",
       "2017-12-05  51260.0  50020.0  52000.0  52100.0  51560.0 -1240.0   740.0   \n",
       "2017-12-06  50020.0  50740.0  51780.0  51320.0  49140.0   720.0  1760.0   \n",
       "2017-12-07  50740.0  52000.0  52100.0  51060.0  49700.0  1260.0  1360.0   \n",
       "\n",
       "             Diff5  Diff10  Diff1_per  Diff3_per  Diff5_per  Diff10_per  \\\n",
       "Date                                                                      \n",
       "2017-12-01  1160.0  -220.0       0.98      -1.61       2.28       -0.43   \n",
       "2017-12-04   440.0  -140.0      -0.16      -1.17       0.86       -0.27   \n",
       "2017-12-05   840.0   300.0      -2.42       1.44       1.64        0.59   \n",
       "2017-12-06  1300.0  -880.0       1.44       3.52       2.60       -1.76   \n",
       "2017-12-07   320.0 -1040.0       2.48       2.68       0.63       -2.05   \n",
       "\n",
       "           Diff1_clf Diff3_clf Diff5_clf Diff10_clf  \n",
       "Date                                                 \n",
       "2017-12-01         1        -1         1         -1  \n",
       "2017-12-04        -1        -1         1         -1  \n",
       "2017-12-05        -1         1         1          1  \n",
       "2017-12-06         1         1         1         -1  \n",
       "2017-12-07         1         1         1         -1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 인스턴스 생성\n",
    "cls = data_import_preprocess()\n",
    "\n",
    "df_news = cls.news_get('./Dataset/삼성전자.csv')\n",
    "df_news = cls.news_timecleansing(df_news)\n",
    "df_news = cls.noun_extracting(df_news, okt)\n",
    "\n",
    "df_stock = cls.stock_get(\"005930.KS\", \"2017-12-01\", \"2019-01-08\")\n",
    "\n",
    "df_news_stock = cls.news_stock_concat(df_news, df_stock)\n",
    "df_news_stock_new = cls.making_new_columns(df_news_stock)\n",
    "df_news_stock_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 최종결과물 확인\n",
    "- 3만 넘으면 Ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36402"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_news_stock_new)\n",
    "len(df_news_stock_new.iloc[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-1. 통계분류로 예측(SVC, NaiveBaysian)\n",
    "## Vectorization => countervec + tf/idf로 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "count_vect = CountVectorizer()\n",
    "TfidfTransformer()\n",
    "\n",
    "# 파이프라인 쓰는법도 고려해보자!!!! 더 쉽고 간결함\n",
    "# 시각화 함수도 넣으면 좋을듯? \n",
    "class Vector():\n",
    "    \n",
    "    def CounterVec_tfidf(self, df, n, k, ratio):\n",
    "        # DataFrame에서 필요한 칼럼추출 => split\n",
    "        X = df['NOUNS']\n",
    "        y = df.loc[:, ['Diff' + n + '_clf']]\n",
    "        \n",
    "        # 카운터벡터\n",
    "        X_vec = count_vect.fit_transform(X)\n",
    "        \n",
    "        # tfidf 가중치 적용\n",
    "        tfidf_transformer = TfidfTransformer(use_idf = True).fit(X_vec) \n",
    "        X_vec_tfidf = tfidf_transformer.transform(X_vec)\n",
    "        \n",
    "        # chi2 변수선택\n",
    "        X_vec_tfidf_chi2 = SelectKBest(chi2, k = k).fit_transform(X_vec_tfidf, y)\n",
    "\n",
    "        # train / test 나누기\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_vec_tfidf_chi2, y, test_size = ratio)\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test, tfidf_transformer\n",
    "    \n",
    "\n",
    "    # import할 모델이름 => doc2vec_no_pos_tagging.model\n",
    "    def Doc_model_import(self, filepath):\n",
    "        model_wikinews = Doc2Vec.load(filepath)\n",
    "        return model_wikinews\n",
    "    \n",
    "\n",
    "    def Doc_vector(self, model, df, n, ratio):\n",
    "        model_wikinews = model\n",
    "        \n",
    "        X = df['NOUNS']\n",
    "        y = df.loc[:, ['Diff' + n + '_clf']]\n",
    "        \n",
    "        \n",
    "        X_corpus_vectors = []\n",
    "        for i in X:\n",
    "            infer_vectors = model_wikinews.infer_vector(i)\n",
    "            X_corpus_vectors.append(infer_vectors)\n",
    "        print('뽑아낸 Vector 크기 : {}'.format(len(X_corpus_vectors)))\n",
    "            \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_corpus_vectors, y, test_size = ratio)\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "        \n",
    "        \n",
    "# 일단 상속은 받아놓고 시작\n",
    "class classification(Vector): \n",
    "    \n",
    "    def NB_tfidf(self, X_train_vec, X_test_vec, y_train, y_test):\n",
    "        MultinomialNB(alpha = 1.0, class_prior = None, fit_prior = True)\n",
    "        clf_nb = MultinomialNB()\n",
    "        clf_nb.fit(X_train_vec, y_train)\n",
    "        \n",
    "        #predicted = clf_tfidf.predict(X_test_vec)\n",
    "        #print('tfidf로 변환한 예측률 :',np.mean(predicted == y_test))\n",
    "        \n",
    "        print('훈련 셋 검증결과 : {:.3f}.'.format(clf_nb.score(X_train, y_train)))\n",
    "        print('테스트 셋 검증결과 : {:.3f}.'.format(clf_nb.score(X_test, y_test)))\n",
    "        #print('UP/Down 예측값 : {:.3f}.'.format(clf_nb.predict_proba(X_test)))  만드는 중\n",
    "        print(clf_nb.predict(X_train))\n",
    "        \n",
    "\n",
    "    # [과제]gamma는 0.1 / c는 10 디폴트로 설정해보자\n",
    "    # 1param - Xdata / 2param - ydata / 3param - ratio / 4param - N일 뒤 예측(1,3,5,10)\n",
    "    def SVC_tfidf(self, X_train_vec, X_test_vec, y_train, y_test):  # ratio - 0.2 / gamma - 0.1 / c - 10 디폴트하거나 파라미터 삭제\n",
    "        clf_svc = SVC(gamma = 0.1, class_weight = \"balanced\", kernel = 'rbf', C = 10)\n",
    "        clf_svc.fit(X_train_vec, y_train)\n",
    "        \n",
    "        print('훈련 셋 검증결과 : {:.3f}.'.format(clf_svc.score(X_train_vec, y_train)))\n",
    "        print('테스트 셋 검증결과 : {:.3f}.'.format(clf_svc.score(X_test_vec, y_test)))\n",
    "        #print(clf_svc.predict_proba(X_test))\n",
    "        print(clf_svc.predict(X_train))\n",
    "    \n",
    "    \n",
    "        # 퍼센트 안내멘트를 리턴하면 될듯?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 테스트 실행1 - countVec + Naive Baysian 분류기\n",
    "- 한글설명 : https://datascienceschool.net/view-notebook/c19b48e3c7b048668f2bb0a113bd25f7/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 셋 검증결과 : 0.639.\n",
      "테스트 셋 검증결과 : 0.490.\n",
      "[-1  1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1\n",
      " -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1  1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1  1 -1 -1 -1 -1 -1  1 -1 -1\n",
      " -1 -1  1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1  1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1  1 -1 -1 -1  1 -1  1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sbg02\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# 이전 모듈 결과값 : df_news_stock_new\n",
    "vec = Vector()\n",
    "clf = classification()\n",
    "\n",
    "X_train, X_test, y_train, y_test, tfidf_transformer = vec.CounterVec_tfidf(df_news_stock_new, n = '1', k = 20000, ratio = 0.2)\n",
    "nb = clf.NB_tfidf(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 테스트 실행2 - countVec + Kernel SVM 분류기\n",
    "- 한글설명 : https://tensorflow.blog/파이썬-머신러닝/2-3-7-커널-서포트-벡터-머신/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sbg02\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 셋 검증결과 : 0.965.\n",
      "테스트 셋 검증결과 : 0.745.\n",
      "[ 1  1 -1 -1 -1  1 -1 -1  1  1 -1 -1 -1 -1  1  1  1 -1  1 -1 -1  1  1  1\n",
      " -1  1  1 -1 -1  1  1 -1  1  1 -1 -1  1 -1 -1 -1 -1 -1  1  1 -1  1 -1 -1\n",
      " -1  1  1 -1 -1 -1 -1  1 -1  1 -1  1  1  1  1 -1  1  1 -1  1 -1 -1 -1  1\n",
      "  1  1 -1 -1 -1 -1  1  1  1 -1 -1  1 -1 -1 -1 -1 -1 -1  1  1  1  1 -1  1\n",
      " -1 -1 -1 -1  1 -1 -1 -1  1  1  1  1  1 -1  1  1  1 -1  1 -1 -1  1  1  1\n",
      " -1 -1  1 -1 -1  1  1  1 -1 -1 -1  1  1  1  1  1 -1  1 -1  1  1 -1 -1 -1\n",
      " -1 -1  1 -1  1  1  1 -1 -1 -1  1 -1  1 -1  1  1 -1 -1 -1  1  1 -1  1  1\n",
      " -1  1  1  1  1 -1 -1 -1  1 -1  1 -1  1  1 -1 -1 -1  1 -1  1 -1 -1  1 -1\n",
      "  1  1 -1  1  1 -1 -1  1 -1  1]\n"
     ]
    }
   ],
   "source": [
    "vec = Vector()\n",
    "clf = classification()\n",
    "\n",
    "X_train, X_test, y_train, y_test = vec.CounterVec_tfidf(df_news_stock_new, n = '1', k = 10000, ratio = 0.2)\n",
    "nb = clf.SVC_tfidf(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-2. 통계분류로 예측(svc, NaiveBaysian)\n",
    "## Vectorization => Doc2Vec으로 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 테스트 실행3 - Doc2Vec + Kernel SVM 분류기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "뽑아낸 Vector 크기 : 253\n"
     ]
    }
   ],
   "source": [
    "vec = Vector()\n",
    "clf = classification()\n",
    "\n",
    "# 모델 임포트하는데 시간 좀 걸립니다. ㅠ / 모델 합치면 6G정도, 웬만한 노트북은 디스크 긁으면서 돌아갑니다.\n",
    "model = vec.Doc_model_import('./Doc2VecClf/doc2vec_no_pos_tagging.model')\n",
    "\n",
    "# 함수에 모델 넣는것도 오래걸린다 ㅠ\n",
    "X_train, X_test, y_train, y_test = vec.Doc_vector(model, df_news_stock_new, n = '5', ratio = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "뽑아낸 Vector 크기 : 253\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = vec.Doc_vector(model, df_news_stock_new, n = '10', ratio = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 셋 검증결과 : 1.000.\n",
      "테스트 셋 검증결과 : 0.627.\n",
      "[-1 -1  1  1  1  1 -1  1 -1 -1 -1 -1 -1  1  1 -1  1  1 -1 -1  1 -1  1 -1\n",
      " -1 -1  1 -1 -1 -1  1 -1 -1  1 -1 -1 -1 -1  1 -1 -1 -1 -1  1 -1  1 -1 -1\n",
      " -1  1 -1 -1 -1  1 -1 -1  1 -1 -1 -1  1 -1 -1 -1 -1 -1  1  1  1 -1  1 -1\n",
      "  1  1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1  1 -1  1  1 -1 -1 -1  1 -1  1 -1\n",
      "  1  1 -1 -1  1 -1  1  1 -1 -1 -1 -1 -1 -1  1  1  1  1 -1  1  1  1  1 -1\n",
      " -1  1  1 -1 -1 -1 -1 -1  1 -1  1 -1  1 -1 -1  1 -1 -1 -1  1 -1 -1 -1 -1\n",
      "  1 -1  1 -1  1 -1 -1 -1  1 -1  1 -1 -1  1 -1 -1 -1  1 -1  1 -1 -1  1 -1\n",
      " -1  1 -1  1  1 -1 -1  1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1  1 -1 -1 -1  1\n",
      " -1  1 -1 -1  1  1 -1  1 -1 -1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sbg02\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "vec = Vector()\n",
    "clf = classification()\n",
    "\n",
    "svc = clf.SVC_tfidf(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: gensim\n",
      "Version: 3.7.0\n",
      "Summary: Python framework for fast Vector Space Modelling\n",
      "Home-page: http://radimrehurek.com/gensim\n",
      "Author: Radim Rehurek\n",
      "Author-email: me@radimrehurek.com\n",
      "License: LGPLv2.1\n",
      "Location: c:\\users\\sbg02\\anaconda3\\lib\\site-packages\n",
      "Requires: six, smart-open, numpy, scipy\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 테스트 실행4 - Doc2Vec + Naive Baysian 분류기\n",
    "- 코드는 이상 없는데, doc2vec에서 벡터를 추출하면 음수값이 섞여있으서 분류기 학습이 안된다.ㅠ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = Vector()\n",
    "clf = classification()\n",
    "\n",
    "svc = clf.NB_tfidf(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#count_vect = CountVectorizer()\n",
    "\n",
    "\n",
    "# 파이프라인 쓰는법도 고려해보자!!!! 더 쉽고 간결함\n",
    "# 시각화 함수도 넣으면 좋읗듯? \n",
    "class VectorFeature():\n",
    "    \n",
    "    def split_vectorize(self, df, n, ratio):\n",
    "        # DataFrame에서 필요한 칼럼추출 => split\n",
    "        X = df['NOUNS']\n",
    "        y = df.loc[:, ['Diff'+n+'_clf']]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = ratio)\n",
    "        \n",
    "        \n",
    "        # 벡터화+tf/idf 해주는 pipeline 설계\n",
    "        makevector = Pipeline([\n",
    "            ('vect', CountVectorizer()),\n",
    "            ('tfidf', TfidfTransformer()),\n",
    "        ])\n",
    "        \n",
    "                \n",
    "        # 벡터화 진행 후 저장(X_data만  실시)\n",
    "        X_train_vec = makevector(X_train)\n",
    "        X_test_vec = makevector(X_test)\n",
    "        return X_train_vec, X_test_vec, y_train, y_test\n",
    "    \n",
    "    \n",
    "    # k =15000정도 괜춘\n",
    "    def feature_Select(self, X_train_vec, X_test_vec, y_train, y_test, k):\n",
    "        # X벡터를 y값과 비교해 카이제곱검정으로 벡터 축소\n",
    "        X_train_chi2 = SelectKBest(chi2, k = k).fit_transform(X_train_vec, y_train)\n",
    "        X_test_chi2 = SelectKBest(chi2, k = k).fit_transform(X_test_vec, y_test)\n",
    "        print(X_train_chi2.shape)\n",
    "        print(X_test_chi2.shape)\n",
    "        return X_train_chi2, X_test_chi2\n",
    "    \n",
    "    \n",
    "''' 위 함수에 메소드 오버라이딩해보면 좋을 듯?\n",
    "    super().feature_Select(X_train_vec, y,  k)   이렇게...?\n",
    "\n",
    "\n",
    "    # k =15000정도 괜춘\n",
    "    def feature_Select(self, X_train_vec, X_test_vec, y_train, y_test, k):\n",
    "        # X벡터를 y값과 비교해 카이제곱검정으로 벡터 축소\n",
    "        X_train_chi2 = SelectKBest(chi2, k = k).fit_transform(X_train_vec, y_train)\n",
    "        X_test_chi2 = SelectKBest(chi2, k = k).fit_transform(X_test_vec, y_test)\n",
    "        print(X_train_chi2.shape)\n",
    "        print(X_test_chi2.shape)\n",
    "        return X_train_chi2, X_test_chi2\n",
    "'''\n",
    "    \n",
    "class classification(VectorFeature): \n",
    "    \n",
    "    def NB_tfidf(self, X_train_vec, X_test_vec, y_train, y_test):\n",
    "        MultinomialNB(alpha = 1.0, class_prior = None, fit_prior = True)\n",
    "        clf_nb = MultinomialNB()\n",
    "        clf_nb.fit(X_train_vec, y_train)\n",
    "        \n",
    "        #predicted = clf_tfidf.predict(X_test_vec)\n",
    "        #print('tfidf로 변환한 예측률 :',np.mean(predicted == y_test))\n",
    "        \n",
    "        print('훈련 셋 검증결과 : {:.3f}.'.format(clf_nb.score(X_train, y_train)))\n",
    "        print('테스트 셋 검증결과 : {:.3f}.'.format(clf_nb.score(X_test, y_test)))\n",
    "        #print('UP/Down 예측값 : {:.3f}.'.format(clf_nb.predict_proba(X_test)))  만드는 중\n",
    "        print(clf_nb.predict(X_train))\n",
    "        \n",
    "\n",
    "    # [과제]gamma는 0.1 / c는 10 디폴트로 설정해보자\n",
    "    # 1param - Xdata / 2param - ydata / 3param - ratio / 4param - N일 뒤 예측(1,3,5,10)\n",
    "    def SVC_tfidf(self, X_train_vec, X_test_vec, y_train, y_test):  # ratio - 0.2 / gamma - 0.1 / c - 10 디폴트하거나 파라미터 삭제\n",
    "        clf_svc = SVC(gamma = 0.1, class_weight = \"balanced\", kernel = 'rbf', C = 10)\n",
    "        clf_svc.fit(X_train_vec, y_train)\n",
    "        \n",
    "        print('훈련 셋 검증결과 : {:.3f}.'.format(clf_svc.score(X_train_vec, y_train)))\n",
    "        print('테스트 셋 검증결과 : {:.3f}.'.format(clf_svc.score(X_test_vec, y_test)))\n",
    "        #print(clf_svc.predict_proba(X_test))\n",
    "        print(clf_svc.predict(X_train))\n",
    "    \n",
    "    \n",
    "        # 퍼센트 안내멘트를 리턴하면 될듯?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # param1 - data / param2 - testSet 비율\n",
    "    # X_train과 X_test만 벡터화시키면 된다. y는 그냥 칼럼 슬라이싱만 하면 ok(아직은 y값 2진분류)\n",
    "    def split_vectorize(df, ratio):        \n",
    "        # Train data 벡터 + tf/idf\n",
    "        X_train_counts = count_vect.fit_transform(X) \n",
    "        tfidf_transformer = TfidfTransformer(use_idf=True).fit(X_train_counts) \n",
    "        X_train_tfidf = tfidf_transformer.transform(X_train_counts)\n",
    "        \n",
    "        # Test data 벡터 + tf/idf\n",
    "        X_test_counts = count_vect.transform(X)\n",
    "        X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "\n",
    "        return (X_train_tfidf, X_test_tfidf, y_train, y_test)\n",
    "        \n",
    "    # 아직 y슬라이싱 안하고 집어넣음 =-> 수정 보완 ㄱㄱㄱㄱㄱㄱㄱㄱㄱㄱ \n",
    "    def NB_tfidf(df):\n",
    "        clf_train = MultinomialNB().fit(X_train_tfidf, y_train)\n",
    "        predicted_train = clf_tfidf.predict(X_train_tfidf)\n",
    "        print('======== Train데이터 예측률 ========')\n",
    "        print('tfidf로 변환한 예측률 :', np.mean(predicted_train == y_train))\n",
    "        \n",
    "        clf_test = MultinomialNB().fit(X_test_tfidf, y_test)\n",
    "        print('======== Test데이터 예측률 ========')\n",
    "        print('tfidf로 변환한 예측률 :', np.mean(clf_test == y_test))\n",
    "        return 뭘 뽑아야 할까요`~?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
